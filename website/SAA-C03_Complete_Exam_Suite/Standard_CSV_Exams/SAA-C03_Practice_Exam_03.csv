Question,Question Text,A,B,C,D,E,Your Answer,Correct,Points,Domain
Q1,A company's production environment consists of Amazon EC2 On-Demand Instances that run constantly between Monday and Saturday. The instances must run for only 12 hours on Sunday and cannot tolerate interruptions. The company wants to cost-optimize the production environment. Which solution will meet these requirements MOST cost-effectively? 12 hours on Sunday. Purchase Standard Reserved Instances for the EC2 instances that run constantly between Monday and Saturday. only 12 hours on Sunday. Purchase Standard Reserved Instances for the EC2 instances that run constantly between Monday and Saturday. Purchase Standard Reserved Instances for the EC2 instances that run constantly between Monday and Saturday. Purchase Convertible Reserved Instances for the EC2 instances that run constantly between Monday and Saturday.,Purchase Scheduled Reserved Instances for the EC2 instances that run for only,Purchase Convertible Reserved Instances for the EC2 instances that run for,Use Spot Instances for the EC2 instances that run for only 12 hours on Sunday.,Use Spot Instances for the EC2 instances that run for only 12 hours on Sunday.,,,A,"=IF(H2=I2,1,0)",Design Cost-Optimized Architectures
Q2,A company runs its production workload on an Amazon Aurora MySQL DB cluster that includes six Aurora Replicas. The company wants near-real-time reporting queries from one of its departments to be automatically distributed across three of the Aurora Replicas. Those three replicas have a different compute and memory specification from the rest of the DB cluster. Which solution meets these requirements? 592 Global IT Certification Hub,Create and use a custom endpoint for the workload,Create a three-node cluster clone and use the reader endpoint,Use any of the instance endpoints for the selected three nodes,Use the reader endpoint to automatically distribute the read-only workload,,,A,"=IF(H3=I3,1,0)",General
Q3,A company uses an Amazon DynamoDB table to store data that the company receives from devices. The DynamoDB table supports a customer-facing website to display recent activity on customer devices. The company configured the table with provisioned throughput for writes and reads. The company wants to calculate performance metrics for customer device data on a daily basis. The solution must have minimal effect on the table's provisioned read and write capacity. Which solution will meet these requirements? connector to calculate performance metrics on a recurring schedule. calculate performance metrics on a recurring schedule. a recurring schedule. performance metrics on a recurring schedule.,Use an Amazon Athena SQL query with the Amazon Athena DynamoDB,Use an AWS Glue job with the AWS Glue DynamoDB export connector to,Use an Amazon Redshift COPY command to calculate performance metrics on,Use an Amazon EMR job with an Apache Hive external table to calculate,,,B,"=IF(H4=I4,1,0)",Design High-Performing Architectures
Q4,A company hosts an application on AWS. The application gives users the ability to upload photos and store the photos in an Amazon S3 bucket. The company wants to use Amazon CloudFront and a custom domain name to upload the photo files to the S3 bucket in the eu-west-1 Region. Which solution will meet these requirements? (Choose two.) us-east-1 Region. Use the certificate in CloudFront. Use the certificate in CloudFront. Acceleration. (OAC). 611 Global IT Certification Hub S3 website endpoint.,Use AWS Certificate Manager (ACM) to create a public certificate in the,Use AWS Certificate Manager (ACM) to create a public certificate in eu-west-1.,Configure Amazon S3 to allow uploads from CloudFront. Configure S3 Transfer,Configure Amazon S3 to allow uploads from CloudFront origin access control,Configure Amazon S3 to allow uploads from CloudFront. Configure an Amazon,,AD,"=IF(H5=I5,1,0)",Design High-Performing Architectures
Q5,A company has an application that uses an Amazon DynamoDB table for storage. A solutions architect discovers that many requests to the table are not returning the latest data. The company's users have not reported any other issues with database performance. Latency is in an acceptable range. 454 Global IT Certification Hub Which design change should the solutions architect recommend? qnH,Add read replicas to the table.,Use a global secondary index (GSI).,Request strongly consistent reads for the table.,Request eventually consistent reads for the table.,,,C,"=IF(H6=I6,1,0)",Design High-Performing Architectures
Q6,A company wants to add its existing AWS usage cost to its operation cost dashboard. A solutions architect needs to recommend a solution that will give the company access to its usage cost programmatically. The company must be able to access cost data for the current year and forecast costs for the next 12 months. Which solution will meet these requirements with the LEAST operational overhead? pagination. report .CSV files. through FTP. company through SMTP.,Access usage cost-related data by using the AWS Cost Explorer API with,Access usage cost-related data by using downloadable AWS Cost Explorer,Configure AWS Budgets actions to send usage cost data to the company,Create AWS Budgets reports for usage cost data. Send the data to the,,,A,"=IF(H7=I7,1,0)",Design Cost-Optimized Architectures
Q7,A company needs to keep user transaction data in an Amazon DynamoDB table. The company must retain the data for 7 years. What is the MOST operationally efficient solution that meets these requirements? table. Store the backup in an Amazon S3 bucket. Set an S3 Lifecycle configuration for the S3 bucket. AWS Lambda function. Configure the Lambda function to back up the table and to store the backup in an Amazon S3 bucket. Set an S3 Lifecycle configuration for the S3 bucket.,Use DynamoDB point-in-time recovery to back up the table continuously.,Use AWS Backup to create backup schedules and retention policies for the,Create an on-demand backup of the table by using the DynamoDB console.,Create an Amazon EventBridge (Amazon CloudWatch Events) rule to invoke an,,,B,"=IF(H8=I8,1,0)",Design Resilient Architectures
Q8,A company is building an application in the AWS Cloud. The application will store data in Amazon S3 buckets in two AWS Regions. The company must use an AWS Key Management Service (AWS KMS) customer managed key to encrypt all data that is stored in the S3 buckets. The data in both S3 buckets must be encrypted and decrypted with the same KMS key. The data and the key must be stored in each of the two Regions. Which solution will meet these requirements with the LEAST operational overhead? server-side encryption with Amazon S3 managed encryption keys (SSE-S3). Configure replication between the S3 buckets. each Region. Configure replication between the S3 buckets. Configure the application to use the KMS key with client-side encryption. Configure the S3 buckets to use server-side encryption with Amazon S3 managed encryption keys (SSE-S3). Configure replication between the S3 buckets. Configure the S3 buckets to use server-side encryption with AWS KMS keys (SSE-KMS). Configure replication between the S3 buckets.,Create an S3 bucket in each Region. Configure the S3 buckets to use,Create a customer managed multi-Region KMS key. Create an S3 bucket in,Create a customer managed KMS key and an S3 bucket in each Region.,Create a customer managed KMS key and an S3 bucket in each Region.,,,B,"=IF(H9=I9,1,0)",Design Secure Architectures
Q9,A solutions architect needs to implement a solution to reduce a company's storage costs. All the company's data is in the Amazon S3 Standard storage class. The company must keep all data for at least 25 years. Data from the most recent 2 years must be highly available and immediately retrievable. Which solution will meet these requirements? immediately. after 2 years. archived in S3 Glacier Deep Archive. Access (S3 One Zone-IA) immediately and to S3 Glacier Deep Archive after 2 years.,Set up an S3 Lifecycle policy to transition objects to S3 Glacier Deep Archive,Set up an S3 Lifecycle policy to transition objects to S3 Glacier Deep Archive,Use S3 Intelligent-Tiering. Activate the archiving option to ensure that data is,Set up an S3 Lifecycle policy to transition objects to S3 One Zone-Infrequent,,,B,"=IF(H10=I10,1,0)",Design Cost-Optimized Architectures
Q10,A company has applications that run on Amazon EC2 instances. The EC2 instances connect to Amazon RDS databases by using an IAM role that has associated policies. The company wants to use AWS Systems Manager to patch the EC2 instances without disrupting the running applications. Which solution will meet these requirements? the new IAM role. Attach the new IAM role to the EC2 instances and the existing IAM role. the IAM user. Configure Systems Manager to use the IAM user to manage the EC2 instances. manage the EC2 instances. AmazonSSMManagedInstanceCore policy to the existing IAM role.,Create a new IAM role. Attach the AmazonSSMManagedInstanceCore policy to,Create an IAM user. Attach the AmazonSSMManagedInstanceCore policy to,Enable Default Host Configuration Management in Systems Manager to,Remove the existing policies from the existing IAM role. Add the,,,C,"=IF(H11=I11,1,0)",Design Secure Architectures
Q11,"A company wants to implement a disaster recovery plan for its primary on-premises file storage volume. The file storage volume is mounted from an Internet Small Computer Systems Interface (iSCSI) device on a local storage server. The file storage volume holds hundreds of terabytes (TB) of data. The company wants to ensure that end users retain immediate access to all file types from the on-premises systems without experiencing latency. Which solution will meet these requirements with the LEAST amount of change to the company's existing infrastructure? on premises. Set the local cache to 10 TB. Modify existing applications to access the files through the NFS protocol. To recover from a disaster, provision an Amazon EC2 instance and mount the S3 bucket that contains the files. to back up all existing data to a virtual tape library. Configure the data backup solution to run nightly after the initial backup is complete. To recover from a disaster, provision an Amazon EC2 instance and restore the data to an Amazon Elastic Block Store (Amazon EBS) volume from the volumes in the virtual tape library. local cache to 10 TB. Mount the Volume Gateway cached volume to the existing file server by using iSCSI, and copy all files to the storage volume. Configure scheduled snapshots of the storage volume. To recover from a disaster, restore a snapshot to an Amazon Elastic Block Store (Amazon EBS) volume and attach the EBS volume to an Amazon EC2 instance. same amount of disk space as the existing file storage volume. Mount the Volume Gateway stored volume to the existing file server by using iSCSI, and copy all files to the storage volume. Configure scheduled snapshots of the storage volume. To recover from a disaster, restore a snapshot to an Amazon Elastic Block Store (Amazon EBS) volume and attach the EBS volume to an Amazon EC2 instance.",Provision an Amazon S3 File Gateway as a virtual machine (VM) that is hosted,Provision an AWS Storage Gateway tape gateway. Use a data backup solution,Provision an AWS Storage Gateway Volume Gateway cached volume. Set the,Provision an AWS Storage Gateway Volume Gateway stored volume with the,,,D,"=IF(H12=I12,1,0)",Design Resilient Architectures
Q12,A recent analysis of a company's IT expenses highlights the need to reduce backup costs. The company's chief information officer wants to simplify the on-premises backup infrastructure and reduce costs by eliminating the use of physical backup tapes. The company must preserve the existing investment in the on-premises backup applications and workflows. What should a solutions architect recommend? the NFS interface. using the NFS interface. using the iSCSI interface. the iSCSI-virtual tape library (VTL) interface.,Set up AWS Storage Gateway to connect with the backup applications using,Set up an Amazon EFS file system that connects with the backup applications,Set up an Amazon EFS file system that connects with the backup applications,Set up AWS Storage Gateway to connect with the backup applications using,,,D,"=IF(H13=I13,1,0)",Design Resilient Architectures
Q13,A hospital recently deployed a RESTful API with Amazon API Gateway and AWS Lambda. The hospital uses API Gateway and Lambda to upload reports that are in PDF format and JPEG format. The hospital needs to modify the Lambda code to identify protected health information (PHI) in the reports. Which solution will meet these requirements with the LEAST operational overhead? the PHI from the extracted text. SageMaker to identify the PHI from the extracted text. Comprehend Medical to identify the PHI from the extracted text. Comprehend Medical to identify the PHI from the extracted text.,Use existing Python libraries to extract the text from the reports and to identify,Use Amazon Textract to extract the text from the reports. Use Amazon,Use Amazon Textract to extract the text from the reports. Use Amazon,Use Amazon Rekognition to extract the text from the reports. Use Amazon,,,C,"=IF(H14=I14,1,0)",General
Q14,"A company needs to store its accounting records in Amazon S3. The records must be immediately accessible for 1 year and then must be archived for an additional 9 years. No one at the company, including administrative users and root users, can be able to delete the records during the entire 10-year period. The records must be stored with maximum resiliency. Which solution will meet these requirements? control policy to deny deletion of the records for a period of 10 years. deletion of the records. After 10 years, change the IAM policy to allow deletion. Glacier Deep Archive after 1 year. Use S3 Object Lock in compliance mode for a period of 10 years. 33 Global IT Certification Hub Zone-Infrequent Access (S3 One Zone-IA) after 1 year. Use S3 Object Lock in governance mode for a period of 10 years.",Store the records in S3 Glacier for the entire 10-year period. Use an access,Store the records by using S3 Intelligent-Tiering. Use an IAM policy to deny,Use an S3 Lifecycle policy to transition the records from S3 Standard to S3,Use an S3 Lifecycle policy to transition the records from S3 Standard to S3 One,,,C,"=IF(H15=I15,1,0)",Design Secure Architectures
Q15,A company has several on-premises Internet Small Computer Systems Interface (ISCSI) network storage servers. The company wants to reduce the number of these servers by moving to the AWS Cloud. A solutions architect must provide low-latency access to frequently used data and reduce the dependency on on-premises servers with a minimal number of infrastructure changes. Which solution will meet these requirements? Amazon S3. 377 Global IT Certification Hub stored volumes. cached volumes.,Deploy an Amazon S3 File Gateway.,Deploy Amazon Elastic Block Store (Amazon EBS) storage with backups to,Deploy an AWS Storage Gateway volume gateway that is configured with,Deploy an AWS Storage Gateway volume gateway that is configured with,,,D,"=IF(H16=I16,1,0)",Design High-Performing Architectures
Q16,"A company has an internal application that runs on Amazon EC2 instances in an Auto Scaling group. The EC2 instances are compute optimized and use Amazon Elastic Block Store (Amazon EBS) volumes. The company wants to identify cost optimizations across the EC2 instances, the Auto Scaling group, and the EBS volumes. Which solution will meet these requirements with the MOST operational efficiency? recommendations for the EC2 instances the Auto Scaling group, and the EBS volumes. recommendations for the EC2 instances, the Auto Scaling group, and the EBS volumes. instances, the Auto Scaling group and the EBS volumes. instances. Create a new AWS Cost and Usage Report. Search the report for cost recommendations for the Auto Scaling group and the EBS volumes.",Create a new AWS Cost and Usage Report. Search the report for cost,Create new Amazon CloudWatch billing alerts. Check the alert statuses for cost,Configure AWS Compute Optimizer for cost recommendations for the EC2,Configure AWS Compute Optimizer for cost recommendations for the EC2,,,C,"=IF(H17=I17,1,0)",Design Cost-Optimized Architectures
Q17,A company runs multiple Amazon EC2 Linux instances in a VPC across two Availability Zones. The instances host applications that use a hierarchical directory structure. The applications need to read and write rapidly and concurrently to shared storage. What should a solutions architect do to meet these requirements? VPC. EFS file system from each EC2 instance. 355 Global IT Certification Hub Store (Amazon EBS) volume. Attach the EBS volume to all the EC2 instances. are attached to each EC2 instance. Synchronize the EBS volumes across the different EC2 instances.,Create an Amazon S3 bucket. Allow access from all the EC2 instances in the,Create an Amazon Elastic File System (Amazon EFS) file system. Mount the,Create a file system on a Provisioned IOPS SSD (io2) Amazon Elastic Block,Create file systems on Amazon Elastic Block Store (Amazon EBS) volumes that,,,B,"=IF(H18=I18,1,0)",Design Secure Architectures
Q18,"A company runs an on-premises application that is powered by a MySQL database. The company is migrating the application to AWS to increase the application's elasticity and availability. The current architecture shows heavy read activity on the database during times of normal operation. Every 4 hours, the company's development team pulls a full 57 Global IT Certification Hub export of the production database to populate a database in the staging environment. During this period, users experience unacceptable application latency. The development team is unable to use the staging environment until the procedure completes. A solutions architect must recommend replacement architecture that alleviates the application latency issue. The replacement architecture also must give the development team the ability to continue using the staging environment without delay. Which solution meets these requirements? Populate the staging database by implementing a backup and restore process that uses the mysqldump utility. database cloning to create the staging database on-demand. production. Use the standby instance for the staging database. production. Populate the staging database by implementing a backup and restore process that uses the mysqldump utility.",Use Amazon Aurora MySQL with Multi-AZ Aurora Replicas for production.,Use Amazon Aurora MySQL with Multi-AZ Aurora Replicas for production. Use,Use Amazon RDS for MySQL with a Multi-AZ deployment and read replicas for,Use Amazon RDS for MySQL with a Multi-AZ deployment and read replicas for,,,B,"=IF(H19=I19,1,0)",Design Resilient Architectures
Q19,"An Amazon EC2 administrator created the following policy associated with an IAM group containing several users: What is the effect of this policy? { ""Version"": ""2012-10-17"", ""Statement"": [ % { ""Effect"": ""Allow"", ""Action"": c2:TerminateInstances"", ""Resource"": ""*"", ""Condition"": { ""IpAddress"": { ""aws:SourceIp"": ""10.100.100.0/24"" } } { ""Effect"": ""Deny"", ""Action"": ""ec2:*"", ""Resource"": ""*"", ""Condition"": { ""StringNotEquals"": { ""ec2:Region"": ""us-east-1"" } } } ] } us-east-1 Region. source IP is 10.100.100.254. user's source IP is 10.100.100.254.",Users can terminate an EC2 instance in any AWS Region except us-east-1.,Users can terminate an EC2 instance with the IP address 10.100.100.1 in the,Users can terminate an EC2 instance in the us-east-1 Region when the user's,Users cannot terminate an EC2 instance in the us-east-1 Region when the,,,C,"=IF(H20=I20,1,0)",Design Secure Architectures
Q20,"A company is hosting a high-traffic static website on Amazon S3 with an Amazon CloudFront distribution that has a default TTL of 0 seconds. The company wants to implement caching to improve performance for the website. However, the company also wants to ensure that stale content is not served for more than a few minutes after a deployment. Which combination of caching methods should a solutions architect implement to meet these requirements? (Choose two.) responses. Configure the function to run on viewer response. S3. On deployment, create a CloudFront invalidation to clear any changed files from edge caches.",Set the CloudFront default TTL to 2 minutes.,Set a default TTL of 2 minutes on the S3 bucket.,Add a Cache-Control private directive to the objects in Amazon S3.,Create an AWS Lambda@Edge function to add an Expires header to HTTP,Add a Cache-Control max-age directive of 24 hours to the objects in Amazon,,AE,"=IF(H21=I21,1,0)",Design High-Performing Architectures
Q21,"A solutions architect is using an AWS CloudFormation template to deploy a three-tier web application. The web application consists of a web tier and an application tier that stores and retrieves user data in Amazon DynamoDB tables. The web and application tiers are hosted on Amazon EC2 instances, and the database tier is not publicly accessible. The application EC2 instances need to access the DynamoDB tables without exposing API credentials in the template. What should the solutions architect do to meet these requirements? 349 Global IT Certification Hub application instances by referencing an instance profile. DynamoDB tables. Add the role to the EC2 instance profile, and associate the instance profile with the application instances. user input access and secret keys from an already-created IAM user that has the required permissions to read and write from the DynamoDB tables. permissions to read and write from the DynamoDB tables. Use the GetAtt function to retrieve the access and secret keys, and pass them to the application instances through the user data.",Create an IAM role to read the DynamoDB tables. Associate the role with the,Create an IAM role that has the required permissions to read and write from the,Use the parameter section in the AWS CloudFormation template to have the,Create an IAM user in the AWS CloudFormation template that has the required,,,B,"=IF(H22=I22,1,0)",Design Secure Architectures
Q22,A company has a financial application that produces reports. The reports average 50 KB in size and are stored in Amazon S3. The reports are frequently 346 Global IT Certification Hub accessed during the first week after production and must be stored for several years. The reports must be retrievable within 6 hours. Which solution meets these requirements MOST cost-effectively? Glacier after 7 days. Standard-Infrequent Access (S3 Standard-IA) after 7 days. reports to S3 Standard-Infrequent Access (S3 Standard-IA) and S3 Glacier. Glacier Deep Archive after 7 days.,Use S3 Standard. Use an S3 Lifecycle rule to transition the reports to S3,Use S3 Standard. Use an S3 Lifecycle rule to transition the reports to S3,Use S3 Intelligent-Tiering. Configure S3 Intelligent-Tiering to transition the,Use S3 Standard. Use an S3 Lifecycle rule to transition the reports to S3,,,A,"=IF(H23=I23,1,0)",Design Cost-Optimized Architectures
Q23,A company's infrastructure consists of Amazon EC2 instances and an Amazon RDS DB instance in a single AWS Region. The company wants to back up its data in a separate Region. Which solution will meet these requirements with the LEAST operational overhead? Region. RDS backups to the separate Region. 108 Global IT Certification Hub to the separate Region. Create a read replica for the RDS DB instance in the separate Region. snapshots to the separate Region. Create RDS snapshots. Export the RDS snapshots to Amazon S3. Configure S3 Cross-Region Replication (CRR) to the separate Region.,Use AWS Backup to copy EC2 backups and RDS backups to the separate,Use Amazon Data Lifecycle Manager (Amazon DLM) to copy EC2 backups and,Create Amazon Machine Images (AMIs) of the EC2 instances. Copy the AMIs,Create Amazon Elastic Block Store (Amazon EBS) snapshots. Copy the EBS,,,A,"=IF(H24=I24,1,0)",Design Resilient Architectures
Q24,"A company is creating a new web application for its subscribers. The application will consist of a static single page and a persistent database layer. The application will have millions of users for 4 hours in the morning, but the application will have only a few thousand users during the rest of the day. The company's data architects have requested the ability to rapidly evolve their schema. Which solutions will meet these requirements and provide the MOST scalability? (Choose two.) capacity. engine mode. auto scaling is enabled. CloudFront distribution with the S3 bucket as the origin. instances in Auto Scaling groups. Configure the instances to periodically refresh the content from an Amazon Elastic File System (Amazon EFS) volume.",Deploy Amazon DynamoDB as the database solution. Provision on-demand,Deploy Amazon Aurora as the database solution. Choose the serverless DB,Deploy Amazon DynamoDB as the database solution. Ensure that DynamoDB,Deploy the static content into an Amazon S3 bucket. Provision an Amazon,Deploy the web servers for static content across a fleet of Amazon EC2,,AD,"=IF(H25=I25,1,0)",Design High-Performing Architectures
Q25,A company runs an ecommerce application on AWS. Amazon EC2 instances process purchases and store the purchase details in an Amazon Aurora PostgreSQL DB cluster. Customers are experiencing application timeouts during times of peak usage. A solutions architect needs to rearchitect the application so that the application can scale to meet peak usage demands. Which combination of actions will meet these requirements MOST cost-effectively? (Choose two.) until the processing is complete. Update the applications to connect to the DB cluster by using Amazon RDS Proxy. Aurora PostgreSQL DB cluster. Queue Service (Amazon SQS) queue. Configure an Auto Scaling group of new EC2 instances that read from the SQS queue. processing is complete.,Configure an Auto Scaling group of new EC2 instances to retry the purchases,Configure the application to use an Amazon ElastiCache cluster in front of the,Update the application to send the purchase requests to an Amazon Simple,Configure an AWS Lambda function to retry the ticket purchases until the,Configure an Amazon AP! Gateway REST API with a usage plan.,,AC,"=IF(H26=I26,1,0)",Design Cost-Optimized Architectures
Q26,A company is using a centralized AWS account to store log data in various Amazon S3 buckets. A solutions architect needs to ensure that the data is encrypted at rest before the data is uploaded to the S3 buckets. The data also must be encrypted in transit. Which solution meets these requirements? buckets. buckets. managed encryption keys (SSE-S3) for S3 uploads. default AWS Key Management Service (AWS KMS) key. 167 Global IT Certification Hub,Use client-side encryption to encrypt the data that is being uploaded to the S3,Use server-side encryption to encrypt the data that is being uploaded to the S3,Create bucket policies that require the use of server-side encryption with S3,Enable the security option to encrypt the S3 buckets through the use of a,,,A,"=IF(H27=I27,1,0)",Design Secure Architectures
Q27,"A company has migrated a fleet of hundreds of on-premises virtual machines (VMs) to Amazon EC2 instances. The instances run a diverse fleet of Windows Server versions along with several Linux distributions. The company wants a solution that will automate inventory and updates of the operating systems. The company also needs a summary of common vulnerabilities of each instance for regular monthly reviews. What should a solutions architect recommend to meet these requirements? instances. Configure AWS Security Hub to produce monthly reports. instances. Deploy Amazon Inspector, and configure monthly reports. Config to automate patch installations on the EC2 instances. AWS Config to automate patch installations on the EC2 instances.",Set up AWS Systems Manager Patch Manager to manage all the EC2,Set up AWS Systems Manager Patch Manager to manage all the EC2,"Set up AWS Shield Advanced, and configure monthly reports. Deploy AWS",Set up Amazon GuardDuty in the account to monitor all EC2 instances. Deploy,,,B,"=IF(H28=I28,1,0)",Design Secure Architectures
Q28,A company uses Amazon EC2 instances and stores data on Amazon Elastic Block Store (Amazon EBS) volumes. The company must ensure that all data is encrypted at rest by using AWS Key Management Service (AWS KMS). The company must be able to control rotation of the encryption keys. Which solution will meet these requirements with the LEAST operational overhead? configure automatic key rotation. the EBS volumes.,Create a customer managed key. Use the key to encrypt the EBS volumes.,Use an AWS managed key to encrypt the EBS volumes. Use the key to,Create an external KMS key with imported key material. Use the key to encrypt,Use an AWS owned key to encrypt the EBS volumes.,,,A,"=IF(H29=I29,1,0)",Design Secure Architectures
Q29,A medical company wants to perform transformations on a large amount of clinical trial data that comes from several customers. The company must extract the data from a relational database that contains the customer data. Then the company 633 Global IT Certification Hub will transform the data by using a series of complex rules. The company will load the data to Amazon S3 when the transformations are complete. All data must be encrypted where it is processed before the company stores the data in Amazon S3. All data must be encrypted by using customer-specific keys. Which solution will meet these requirements with the LEAST amount of operational effort? each job that uses server-side encryption with Amazon S3 managed keys (SSE-S3) to encrypt the data. configuration to each cluster that uses client-side encryption with a custom client-side root key (CSE-Custom) to encrypt the data. each job that uses client-side encryption with AWS KMS managed keys (CSE-KMS) to encrypt the data. configuration to each cluster that uses server-side encryption with AWS KMS keys (SSE-KMS) to encrypt the data.,Create one AWS Glue job for each customer. Attach a security configuration to,Create one Amazon EMR cluster for each customer. Attach a security,Create one AWS Glue job for each customer. Attach a security configuration to,Create one Amazon EMR cluster for each customer. Attach a security,,,C,"=IF(H30=I30,1,0)",Design Secure Architectures
Q30,A company's application integrates with multiple software-as-a-service (SaaS) sources for data collection. The company runs Amazon EC2 instances to receive the data and to upload the data to an Amazon S3 bucket for analysis. The same EC2 instance that receives and uploads the data also sends a notification to the user when an upload is complete. The company has noticed slow application performance and wants to improve the performance as much as possible. Which solution will meet these requirements with the LEAST operational overhead? an S3 event notification to send events to an Amazon Simple Notification Service (Amazon SNS) topic when the upload to the S3 bucket is complete. and the S3 bucket. Configure an S3 event notification to send events to an Amazon Simple Notification Service (Amazon SNS) topic when the upload to the S3 bucket is complete. 26 Global IT Certification Hub SaaS source to send output data. Configure the S3 bucket as the rule's target. Create a second EventBridge (Cloud Watch Events) rule to send events when the upload to the S3 bucket is complete. Configure an Amazon Simple Notification Service (Amazon SNS) topic as the second rule's target. containerized application on Amazon Elastic Container Service (Amazon ECS). Configure Amazon CloudWatch Container Insights to send events to an Amazon Simple Notification Service (Amazon SNS) topic when the upload to the S3 bucket is complete.,Create an Auto Scaling group so that EC2 instances can scale out. Configure,Create an Amazon AppFlow flow to transfer data between each SaaS source,Create an Amazon EventBridge (Amazon CloudWatch Events) rule for each,Create a Docker container to use instead of an EC2 instance. Host the,,,B,"=IF(H31=I31,1,0)",Design High-Performing Architectures
Q31,A company has several web servers that need to frequently access a common Amazon RDS MySQL Multi-AZ DB instance. The company wants a secure method for the web servers to connect to the database while meeting a security requirement to rotate user credentials frequently. Which solution meets these requirements? necessary IAM permissions to allow the web servers to access AWS Secrets Manager. Grant the necessary IAM permissions to allow the web servers to access OpsCenter. necessary IAM permissions to allow the web servers to retrieve credentials and access the database. Management Service (AWS KMS) on the web server file system. The web server should be able to decrypt the files and access the database.,Store the database user credentials in AWS Secrets Manager. Grant the,Store the database user credentials in AWS Systems Manager OpsCenter.,Store the database user credentials in a secure Amazon S3 bucket. Grant the,Store the database user credentials in files encrypted with AWS Key,,,A,"=IF(H32=I32,1,0)",Design Secure Architectures
Q32,"A company needs to provide customers with secure access to its data. The company processes customer data and stores the results in an Amazon S3 bucket. All the data is subject to strong regulations and security requirements. The data must be encrypted at rest. Each customer must be able to access only their data from their AWS account. Company employees must not be able to access the data. Which solution will meet these requirements? Encrypt the data client-side. In the private certificate policy, deny access to the certificate for all principals except an IAM role that the customer provides. 432 Global IT Certification Hub customer. Encrypt the data server-side. In the S3 bucket policy, deny decryption of data for all principals except an IAM role that the customer provides. customer. Encrypt the data server-side. In each KMS key policy, deny decryption of data for all principals except an IAM role that the customer provides. Encrypt the data client-side. In the public certificate policy, deny access to the certificate for all principals except an IAM role that the customer provides.",Provision an AWS Certificate Manager (ACM) certificate for each customer.,Provision a separate AWS Key Management Service (AWS KMS) key for each,Provision a separate AWS Key Management Service (AWS KMS) key for each,Provision an AWS Certificate Manager (ACM) certificate for each customer.,,,C,"=IF(H33=I33,1,0)",Design Secure Architectures
Q33,A company is migrating a data center from its on-premises location to AWS. The company has several legacy applications that are hosted on individual virtual servers. Changes to the application designs cannot be made. Each individual virtual server currently runs as its own EC2 instance. A solutions architect needs to ensure that the applications are reliable and fault tolerant after migration to AWS. The applications will run on Amazon EC2 instances. Which solution will meet these requirements? one. Create an Amazon Machine Image (AMI) of each application instance. Use the AMI to create EC2 instances in the Auto Scaling group Configure an Application Load Balancer in front of the Auto Scaling group. each application. Store the backup in Amazon S3 in a separate Availability Zone. Configure a disaster recovery process to restore the EC2 instance for each application from its most recent backup. two new EC2 instances from the AMI. Place each EC2 instance in a separate Availability Zone. Configure a Network Load Balancer that has the EC2 instances as targets. EC2 instance. Break down functionality from each application into individual 557 Global IT Certification Hub components. Host each application on Amazon Elastic Container Service (Amazon ECS) with an AWS Fargate launch type.,Create an Auto Scaling group that has a minimum of one and a maximum of,Use AWS Backup to create an hourly backup of the EC2 instance that hosts,Create an Amazon Machine Image (AMI) of each application instance. Launch,Use AWS Mitigation Hub Refactor Spaces to migrate each application off the,,,A,"=IF(H34=I34,1,0)",Design Resilient Architectures
Q34,"A company wants to run an in-memory database for a latency-sensitive application that runs on Amazon EC2 instances. The application processes more than 100,000 transactions each minute and requires high network throughput. A solutions architect needs to provide a cost-effective network design that minimizes data transfer charges. Which solution meets these requirements? Region. Specify a placement group with cluster strategy when launching EC2 instances. Region. Specify a placement group with partition strategy when launching EC2 189 Global IT Certification Hub instances. Zones based on a network utilization target. instances in different Availability Zones.",Launch all EC2 instances in the same Availability Zone within the same AWS,Launch all EC2 instances in different Availability Zones within the same AWS,Deploy an Auto Scaling group to launch EC2 instances in different Availability,Deploy an Auto Scaling group with a step scaling policy to launch EC2,,,A,"=IF(H35=I35,1,0)",Design Resilient Architectures
Q35,"A company has deployed a web application on AWS. The company hosts the backend database on Amazon RDS for MySQL with a primary DB instance and five read replicas to support scaling needs. The read replicas must lag no more than 1 second behind the primary DB instance. The database routinely runs scheduled stored procedures. As traffic on the website increases, the replicas experience additional lag during periods of peak load. A solutions architect must reduce the replication lag as much as possible. The solutions architect must minimize changes to the application code 209 Global IT Certification Hub and must minimize ongoing operational overhead. Which solution will meet these requirements? Aurora Replicas, and configure Aurora Auto Scaling. Replace the stored procedures with Aurora MySQL native functions. on Modify the application to check the cache before the application queries the database. Replace the stored procedures with AWS Lambda functions. instances. Choose large, compute optimized EC2 instances for all replica nodes. Maintain the stored procedures on the EC2 instances. capacity units (RCUs) to support the required throughput, and configure on-demand capacity scaling. Replace the stored procedures with DynamoDB streams.",Migrate the database to Amazon Aurora MySQL. Replace the read replicas with,Deploy an Amazon ElastiCache for Redis cluster in front of the database.,Migrate the database to a MySQL database that runs on Amazon EC2,Migrate the database to Amazon DynamoDB. Provision a large number of read,,,A,"=IF(H36=I36,1,0)",Design High-Performing Architectures
Q36,"A development team needs to host a website that will be accessed by other teams. The website contents consist of HTML, CSS, client-side JavaScript, and images. Which method is the MOST cost-effective for hosting the website? the Express.js framework.",Containerize the website and host it in AWS Fargate.,Create an Amazon S3 bucket and host the website there.,Deploy a web server on an Amazon EC2 instance to host the website.,Configure an Application Load Balancer with an AWS Lambda target that uses,,,B,"=IF(H37=I37,1,0)",Design Cost-Optimized Architectures
Q37,A company collects data from a large number of participants who use wearable devices. The company stores the data in an Amazon DynamoDB table and uses applications to analyze the data. The data workload is constant and predictable. The company wants to stay at or below its forecasted budget for DynamoDB. Which solution will meet these requirements MOST cost-effectively? (DynamoDB Standard-IA). Reserve capacity for the forecasted workload. capacity units (WCUs). units (WCUs) high enough to accommodate changes in the workload. capacity units (WCUs) with reserved capacity.,Use provisioned mode and DynamoDB Standard-Infrequent Access,Use provisioned mode. Specify the read capacity units (RCUs) and write,Use on-demand mode. Set the read capacity units (RCUs) and write capacity,Use on-demand mode. Specify the read capacity units (RCUs) and write,,,B,"=IF(H38=I38,1,0)",Design Cost-Optimized Architectures
Q38,"A company has thousands of edge devices that collectively generate 1 TB of status alerts each day. Each alert is approximately 2 KB in size. A solutions architect needs to implement a solution to ingest and store the alerts for future analysis. The company wants a highly available solution. However, the company needs to minimize costs and does not want to manage additional infrastructure. Additionally, the company wants to keep 14 days of data available for immediate analysis and archive any data older than 14 days. What is the MOST operationally efficient solution that meets these requirements? Configure the Kinesis Data Firehose stream to deliver the alerts to an Amazon S3 bucket. Set up an S3 Lifecycle configuration to transition data to Amazon S3 Glacier after 14 days. 25 Global IT Certification Hub behind an Elastic Load Balancer to ingest the alerts. Create a script on the EC2 instances that will store the alerts in an Amazon S3 bucket. Set up an S3 Lifecycle configuration to transition data to Amazon S3 Glacier after 14 days. Configure the Kinesis Data Firehose stream to deliver the alerts to an Amazon OpenSearch Service (Amazon Elasticsearch Service) cluster. Set up the Amazon OpenSearch Service (Amazon Elasticsearch Service) cluster to take manual snapshots every day and delete data from the cluster that is older than 14 days. ingest the alerts, and set the message retention period to 14 days. Configure consumers to poll the SQS queue, check the age of the message, and analyze the message data as needed. If the message is 14 days old, the consumer should copy the message to an Amazon S3 bucket and delete the message from the SQS queue.",Create an Amazon Kinesis Data Firehose delivery stream to ingest the alerts.,Launch Amazon EC2 instances across two Availability Zones and place them,Create an Amazon Kinesis Data Firehose delivery stream to ingest the alerts.,Create an Amazon Simple Queue Service (Amazon SQS) standard queue to,,,A,"=IF(H39=I39,1,0)",Design Cost-Optimized Architectures
Q39,A company is building a new dynamic ordering website. The company wants to minimize server maintenance and patching. The website must be highly available and must scale read and write capacity as quickly as possible to meet changes in user demand. 111 Global IT Certification Hub Which solution will meet these requirements? Gateway and AWS Lambda. Use Amazon DynamoDB with on-demand capacity for the database. Configure Amazon CloudFront to deliver the website content. Gateway and AWS Lambda. Use Amazon Aurora with Aurora Auto Scaling for the database. Configure Amazon CloudFront to deliver the website content. group to scale the EC2 instances. Use an Application Load Balancer to distribute traffic. Use Amazon DynamoDB with provisioned write capacity for the database. group to scale the EC2 instances. Use an Application Load Balancer to distribute traffic. Use Amazon Aurora with Aurora Auto Scaling for the database.,Host static content in Amazon S3. Host dynamic content by using Amazon API,Host static content in Amazon S3. Host dynamic content by using Amazon API,Host all the website content on Amazon EC2 instances. Create an Auto Scaling,Host all the website content on Amazon EC2 instances. Create an Auto Scaling,,,A,"=IF(H40=I40,1,0)",Design High-Performing Architectures
Q40,A company is deploying a new application on Amazon EC2 instances. The application writes data to Amazon Elastic Block Store (Amazon EBS) volumes. The company needs to ensure that all data that is written to the EBS volumes is encrypted at rest. Which solution will meet this requirement? instances. EC2 instances. all instances that require encryption at the EBS level. EBS encryption in the account. Ensure that the key policy is active. 255 Global IT Certification Hub,Create an IAM role that specifies EBS encryption. Attach the role to the EC2,Create the EBS volumes as encrypted volumes. Attach the EBS volumes to the,Create an EC2 instance tag that has a key of Encrypt and a value of True. Tag,Create an AWS Key Management Service (AWS KMS) key policy that enforces,,,B,"=IF(H41=I41,1,0)",Design Secure Architectures
Q41,A company hosts a website on Amazon EC2 instances behind an Application Load Balancer (ALB). The website serves static content. Website traffic is increasing. The company wants to minimize the website hosting costs. Which solution will meet these requirements? distribution for the S3 bucket. 558 Global IT Certification Hub cluster for the S3 bucket. website. website.,Move the website to an Amazon S3 bucket. Configure an Amazon CloudFront,Move the website to an Amazon S3 bucket. Configure an Amazon ElastiCache,Move the website to AWS Amplify. Configure an ALB to resolve to the Amplify,Move the website to AWS Amplify. Configure EC2 instances to cache the,,,A,"=IF(H42=I42,1,0)",Design Cost-Optimized Architectures
Q42,"A company's near-real-time streaming application is running on AWS. As the data is ingested, a job runs on the data and takes 30 minutes to complete. The workload frequently experiences high latency due to large amounts of incoming data. A solutions architect needs to design a scalable and serverless solution to enhance performance. Which combination of steps should the solutions architect take? (Choose two.) process the data.",Use Amazon Kinesis Data Firehose to ingest the data.,Use AWS Lambda with AWS Step Functions to process the data.,Use AWS Database Migration Service (AWS DMS) to ingest the data.,Use Amazon EC2 instances in an Auto Scaling group to process the data.,Use AWS Fargate with Amazon Elastic Container Service (Amazon ECS) to,,AE,"=IF(H43=I43,1,0)",Design High-Performing Architectures
Q43,A research laboratory needs to process approximately 8 TB of data. The laboratory requires sub-millisecond latencies and a minimum throughput of 6 GBps for the storage subsystem. Hundreds of Amazon EC2 instances that run Amazon Linux will distribute and process the data. Which solution will meet the performance requirements? policy to ALL. Import the raw data into the file system. Mount the fila system on the EC2 instances. Lustre file system that uses persistent SSD storage. Select the option to import data from and export data to Amazon S3. Mount the file system on the EC2 instances. Lustre file system that uses persistent HDD storage. Select the option to import data from and export data to Amazon S3. Mount the file system on the EC2 instances. 185 Global IT Certification Hub tiering policy to NONE. Import the raw data into the file system. Mount the file system on the EC2 instances.,Create an Amazon FSx for NetApp ONTAP file system. Sat each volume' tiering,Create an Amazon S3 bucket to store the raw data. Create an Amazon FSx for,Create an Amazon S3 bucket to store the raw data. Create an Amazon FSx for,Create an Amazon FSx for NetApp ONTAP file system. Set each volume's,,,B,"=IF(H44=I44,1,0)",Design High-Performing Architectures
Q44,A company is designing its production application's disaster recovery (DR) strategy. The application is backed by a MySQL database on an Amazon Aurora cluster in the us-east-1 Region. The company has chosen the us-west-1 Region as 559 Global IT Certification Hub its DR Region. The company's target recovery point objective (RPO) is 5 minutes and the target recovery time objective (RTO) is 20 minutes. The company wants to minimize configuration changes. Which solution will meet these requirements with the MOST operational efficiency? application's Aurora MySQL cluster writer instance. failover. Service (AWS DMS) to sync both clusters.,Create an Aurora read replica in us-west-1 similar in size to the production,Convert the Aurora cluster to an Aurora global database. Configure managed,Create a new Aurora cluster in us-west-1 that has Cross-Region Replication.,Create a new Aurora cluster in us-west-1. Use AWS Database Migration,,,B,"=IF(H45=I45,1,0)",Design Resilient Architectures
Q45,A company currently runs an on-premises stock trading application by using Microsoft Windows Server. The company wants to migrate the application to the AWS Cloud. The company needs to design a highly available solution that provides low-latency access to block storage across multiple Availability Zones. Which solution will meet these requirements with the LEAST implementation effort? Amazon EC2 instances. Install the application on both cluster nodes. Use Amazon FSx for Windows File Server as shared storage between the two cluster nodes. Amazon EC2 instances. Install the application on both cluster nodes. Use Amazon Elastic Block Store (Amazon EBS) General Purpose SSD (gp3) volumes as storage attached to the EC2 instances. Set up application-level replication to sync data from one EBS volume in one Availability Zone to another EBS volume in the second Availability Zone. Configure one EC2 instance as active and the second EC2 instance in standby mode. Use an Amazon FSx for NetApp ONTAP Multi-AZ file system to access the data by using Internet Small Computer Systems Interface (iSCSI) protocol. Configure one EC2 instance as active and the second EC2 instance in standby mode. Use Amazon Elastic Block Store (Amazon EBS) Provisioned IOPS SSD (io2) volumes as storage attached to the EC2 instances. Set up Amazon EBS level replication to sync data from one io2 volume in one Availability Zone to another io2 volume in the second Availability Zone.,Configure a Windows Server cluster that spans two Availability Zones on,Configure a Windows Server cluster that spans two Availability Zones on,Deploy the application on Amazon EC2 instances in two Availability Zones.,Deploy the application on Amazon EC2 instances in two Availability Zones.,,,C,"=IF(H46=I46,1,0)",Design Resilient Architectures
Q46,An entertainment company is using Amazon DynamoDB to store media metadata. The application is read intensive and experiencing delays. The company does not have staff to handle additional operational overhead and needs to improve the performance efficiency of DynamoDB without reconfiguring the application. What should a solutions architect recommend to meet this requirement?,Use Amazon ElastiCache for Redis.,Use Amazon DynamoDB Accelerator (DAX).,Replicate data by using DynamoDB global tables.,Use Amazon ElastiCache for Memcached with Auto Discovery enabled.,,,B,"=IF(H47=I47,1,0)",Design High-Performing Architectures
Q47,"A solutions architect must migrate a Windows Internet Information Services (IIS) web application to AWS. The application currently relies on a file share hosted in the user's on-premises network-attached storage (NAS). The solutions architect has proposed migrating the IIS web servers to Amazon EC2 instances in multiple Availability Zones that are connected to the storage solution, and configuring an Elastic Load Balancer attached to the instances. Which replacement to the on-premises file share is MOST resilient and durable?",Migrate the file share to Amazon RDS.,Migrate the file share to AWS Storage Gateway.,Migrate the file share to Amazon FSx for Windows File Server.,Migrate the file share to Amazon Elastic File System (Amazon EFS).,,,C,"=IF(H48=I48,1,0)",Design Resilient Architectures
Q48,A company has primary and secondary data centers that are 500 miles (804.7 km) apart and interconnected with high-speed fiber-optic cable. The company needs a highly available and secure network connection between its data centers 535 Global IT Certification Hub and a VPC on AWS for a mission-critical workload. A solutions architect must choose a connection solution that provides maximum resiliency. Which solution meets these requirements? at two Direct Connect locations on two separate devices secondary data centers terminating at one Direct Connect location on the same device data centers terminating at two Direct Connect locations on two separate devices secondary data centers terminating at one Direct Connect location on two separate devices,Two AWS Direct Connect connections from the primary data center terminating,A single AWS Direct Connect connection from each of the primary and,Two AWS Direct Connect connections from each of the primary and secondary,A single AWS Direct Connect connection from each of the primary and,,,C,"=IF(H49=I49,1,0)",Design Secure Architectures
Q49,A company recently migrated a message processing system to AWS. The system receives messages into an ActiveMQ queue running on an Amazon EC2 instance. Messages are processed by a consumer application running on Amazon EC2. The consumer application processes the messages and writes results to a MySQL database running on Amazon EC2. The company wants this application to be highly available with low operational complexity. Which architecture offers the HIGHEST availability? consumer EC2 instance in another Availability Zone. Replicate the MySQL database to another Availability Zone. Zones. Add an additional consumer EC2 instance in another Availability Zone. Replicate the MySQL database to another Availability Zone. Zones. Add an additional consumer EC2 instance in another Availability Zone. Use Amazon RDS for MySQL with Multi-AZ enabled. Zones. Add an Auto Scaling group for the consumer EC2 instances across two Availability Zones. Use Amazon RDS for MySQL with Multi-AZ enabled.,Add a second ActiveMQ server to another Availability Zone. Add an additional,Use Amazon MQ with active/standby brokers configured across two Availability,Use Amazon MQ with active/standby brokers configured across two Availability,Use Amazon MQ with active/standby brokers configured across two Availability,,,D,"=IF(H50=I50,1,0)",Design Resilient Architectures
Q50,A solutions architect is designing a payment processing application that runs on AWS Lambda in private subnets across multiple Availability Zones. The application uses multiple Lambda functions and processes millions of transactions each day. The architecture must ensure that the application does not process duplicate payments. Which solution will meet these requirements? Amazon S3 bucket. Configure the S3 bucket with an event notification to invoke another Lambda function to process the due payments. Amazon Simple Queue Service (Amazon SQS) queue. Configure another Lambda function to poll the SQS queue and to process the due payments. Amazon Simple Queue Service (Amazon SQS) FIFO queue. Configure another Lambda function to poll the FIFO queue and to process the due payments. Amazon DynamoDB table. Configure streams on the DynamoDB table to invoke another Lambda function to process the due payments.,Use Lambda to retrieve all due payments. Publish the due payments to an,Use Lambda to retrieve all due payments. Publish the due payments to an,Use Lambda to retrieve all due payments. Publish the due payments to an,Use Lambda to retrieve all due payments. Store the due payments in an,,,C,"=IF(H51=I51,1,0)",Design Resilient Architectures
Q51,A financial company hosts a web application on AWS. The application uses an Amazon API Gateway Regional API endpoint to give users the ability to retrieve current stock prices. The company's security team has noticed an increase in the number of API requests. The security team is concerned that HTTP flood attacks might take the application offline. 248 Global IT Certification Hub A solutions architect must design a solution to protect the application from this type of attack. Which solution meets these requirements with the LEAST operational overhead? API endpoint with a maximum TTL of 24 hours. web ACL with the API Gateway stage. security team when the predefined rate is reached. API Gateway Regional API endpoint. Create an AWS Lambda function to block requests from IP addresses that exceed the predefined rate.,Create an Amazon CloudFront distribution in front of the API Gateway Regional,Create a Regional AWS WAF web ACL with a rate-based rule. Associate the,Use Amazon CloudWatch metrics to monitor the Count metric and alert the,Create an Amazon CloudFront distribution with Lambda@Edge in front of the,,,B,"=IF(H52=I52,1,0)",Design Secure Architectures
Q52,A company hosts a multi-tier web application on Amazon Linux Amazon EC2 instances behind an Application Load Balancer. The instances run in an Auto Scaling group across multiple Availability Zones. The company observes that the Auto Scaling group launches more On-Demand Instances when the application's end users access high volumes of static web content. The company wants to optimize cost. What should a solutions architect do to redesign the application MOST cost-effectively? On-Demand Instances. On-Demand Instances. an Amazon S3 bucket. 276 Global IT Certification Hub the static website contents.,Update the Auto Scaling group to use Reserved Instances instead of,Update the Auto Scaling group to scale by launching Spot Instances instead of,Create an Amazon CloudFront distribution to host the static web contents from,Create an AWS Lambda function behind an Amazon API Gateway API to host,,,C,"=IF(H53=I53,1,0)",Design Resilient Architectures
Q53,A company has a static website that is hosted on Amazon CloudFront in front of Amazon S3. The static website uses a database backend. The company notices that the website does not reflect updates that have been made in the website's Git repository. The company checks the continuous integration and continuous delivery (CI/CD) pipeline between the Git repository and Amazon S3. The company verifies that the webhooks are configured properly and that the CI/CD pipeline is sending messages that indicate successful deployments. A solutions architect needs to implement a solution that displays the updates on the website. Which solution will meet these requirements? web application.,Add an Application Load Balancer.,Add Amazon ElastiCache for Redis or Memcached to the database layer of the,Invalidate the CloudFront cache.,Use AWS Certificate Manager (ACM) to validate the website's SSL certificate.,,,C,"=IF(H54=I54,1,0)",Design High-Performing Architectures
Q54,"A company uses high block storage capacity to runs its workloads on premises. The company's daily peak input and output transactions per second are not more than 15,000 IOPS. The company wants to migrate the workloads to Amazon EC2 and to provision disk performance independent of storage capacity. Which Amazon Elastic Block Store (Amazon EBS) volume type will meet these 265 Global IT Certification Hub requirements MOST cost-effectively? qnH",GP2 volume type,io2 volume type,GP3 volume type,io1 volume type,,,C,"=IF(H55=I55,1,0)",Design High-Performing Architectures
Q55,"A company has a popular gaming platform running on AWS. The application is sensitive to latency because latency can impact the user experience and introduce unfair advantages to some players. The application is deployed in every AWS Region. It runs on Amazon EC2 instances that are part of Auto Scaling groups configured behind Application Load Balancers (ALBs). A solutions architect needs to implement a mechanism to monitor the health of the application and redirect traffic to healthy endpoints. Which solution meets these requirements? that the application listens on, and attach it to a Regional endpoint in each Region. Add the ALB as the endpoint. server. Configure the cache behavior to use origin cache headers. Use AWS Lambda functions to optimize the traffic. server. Configure the cache behavior to use origin cache headers. Use AWS Lambda functions to optimize the traffic. application. Create a DynamoDB Accelerator (DAX) cluster to act as the in-memory cache for DynamoDB hosting the application data.",Configure an accelerator in AWS Global Accelerator. Add a listener for the port,Create an Amazon CloudFront distribution and specify the ALB as the origin,Create an Amazon CloudFront distribution and specify Amazon S3 as the origin,Configure an Amazon DynamoDB database to serve as the data store for the,,,A,"=IF(H56=I56,1,0)",Design High-Performing Architectures
Q56,"A company hosts a multi-tier web application that uses an Amazon Aurora MySQL DB cluster for storage. The application tier is hosted on Amazon EC2 instances. The company's IT security guidelines mandate that the database credentials be encrypted and rotated every 14 days. 208 Global IT Certification Hub What should a solutions architect do to meet this requirement with the LEAST operational effort? AWS Secrets Manager to create a new secret that uses the KMS key with the appropriate credentials. Associate the secret with the Aurora DB cluster. Configure a custom rotation period of 14 days. user name as a string parameter and one that uses the SecureString type for the password. Select AWS Key Management Service (AWS KMS) encryption for the password parameter, and load these parameters in the application tier. Implement an AWS Lambda function that rotates the password every 14 days. (AWS KMS) encrypted Amazon Elastic File System (Amazon EFS) file system. Mount the EFS file system in all EC2 instances of the application tier. Restrict the access to the file on the file system so that the application can read the file and that only super users can modify the file. Implement an AWS Lambda function that rotates the key in Aurora every 14 days and writes new credentials into the file. (AWS KMS) encrypted Amazon S3 bucket that the application uses to load the credentials. Download the file to the application regularly to ensure that the correct credentials are used. Implement an AWS Lambda function that rotates the Aurora credentials every 14 days and uploads these credentials to the file in the S3 bucket.",Create a new AWS Key Management Service (AWS KMS) encryption key. Use,Create two parameters in AWS Systems Manager Parameter Store: one for the,Store a file that contains the credentials in an AWS Key Management Service,Store a file that contains the credentials in an AWS Key Management Service,,,A,"=IF(H57=I57,1,0)",Design Secure Architectures
Q57,"A solutions architect is designing an application that will allow business users to upload objects to Amazon S3. The solution needs to maximize object durability. Objects also must be readily available at any time and for any length of time. Users will access objects frequently within the first 30 days after the objects are uploaded, but users are much less likely to access objects that are older than 30 days. Which solution meets these requirements MOST cost-effectively? objects to S3 Glacier after 30 days. objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days. objects to S3 One Zone-Infrequent Access (S3 One Zone-IA) after 30 days. transition the objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days.",Store all the objects in S3 Standard with an S3 Lifecycle rule to transition the,Store all the objects in S3 Standard with an S3 Lifecycle rule to transition the,Store all the objects in S3 Standard with an S3 Lifecycle rule to transition the,Store all the objects in S3 Intelligent-Tiering with an S3 Lifecycle rule to,,,B,"=IF(H58=I58,1,0)",Design Cost-Optimized Architectures
Q58,"A company is developing an ecommerce application that will consist of a load-balanced front end, a container-based application, and a relational database. A solutions architect needs to create a highly available solution that operates with as little manual intervention as possible. Which solutions meet these requirements? (Choose two.) Availability Zone. application load. Fargate launch type to handle the dynamic application load. Amazon EC2 launch type to handle the dynamic application load.",Create an Amazon RDS DB instance in Multi-AZ mode.,Create an Amazon RDS DB instance and one or more replicas in another,Create an Amazon EC2 instance-based Docker cluster to handle the dynamic,Create an Amazon Elastic Container Service (Amazon ECS) cluster with a,Create an Amazon Elastic Container Service (Amazon ECS) cluster with an,,AD,"=IF(H59=I59,1,0)",Design Resilient Architectures
Q59,A solutions architect is designing an asynchronous application to process credit card data validation requests for a bank. The application must be secure and be able to process each request at least once. Which solution will meet these requirements MOST cost-effectively? (Amazon SQS) standard queues as the event source. Use AWS Key Management Service (SSE-KMS) for encryption. Add the kms:Decrypt permission for the Lambda execution role. (Amazon SQS) FIFO queues as the event source. Use SQS managed encryption keys (SSE-SQS) for encryption. Add the encryption key invocation permission for the Lambda function. Service (Amazon SQS) FIFO queues as the event source. Use AWS KMS keys (SSE-KMS). Add the kms:Decrypt permission for the Lambda execution role. 308 Global IT Certification Hub Service (Amazon SQS) standard queues as the event source. Use AWS KMS keys (SSE-KMS) for encryption. Add the encryption key invocation permission for the Lambda function.,Use AWS Lambda event source mapping. Set Amazon Simple Queue Service,Use AWS Lambda event source mapping. Use Amazon Simple Queue Service,Use the AWS Lambda event source mapping. Set Amazon Simple Queue,Use the AWS Lambda event source mapping. Set Amazon Simple Queue,,,A,"=IF(H60=I60,1,0)",Design Secure Architectures
Q60,A company has an on-premises application that generates a large amount of time-sensitive data that is backed up to Amazon S3. The application has grown and there are user complaints about internet bandwidth limitations. A solutions architect needs to design a long-term solution that allows for both timely backups to Amazon 27 Global IT Certification Hub S3 and with minimal impact on internet connectivity for internal users. Which solution meets these requirements? endpoint. through this new connection. and return the devices to AWS each day. removal of S3 service limits from the account.,Establish AWS VPN connections and proxy all traffic through a VPC gateway,Establish a new AWS Direct Connect connection and direct backup traffic,Order daily AWS Snowball devices. Load the data onto the Snowball devices,Submit a support ticket through the AWS Management Console. Request the,,,B,"=IF(H61=I61,1,0)",Design Resilient Architectures
Q61,"A solutions architect is creating a new Amazon CloudFront distribution for an application. Some of the information submitted by users is sensitive. The application uses HTTPS but needs another layer of security. The sensitive information should.be protected throughout the entire application stack, and access to the information should be restricted to certain applications. Which action should the solutions architect take? for the Viewer Protocol Policy.",Configure a CloudFront signed URL.,Configure a CloudFront signed cookie.,Configure a CloudFront field-level encryption profile.,Configure CloudFront and set the Origin Protocol Policy setting to HTTPS Only,,,C,"=IF(H62=I62,1,0)",Design Secure Architectures
Q62,A company has deployed a multi-account strategy on AWS by using AWS Control Tower. The company has provided individual AWS accounts to each of its developers. The company wants to implement controls to limit AWS resource costs that the developers incur. Which solution will meet these requirements with the LEAST operational overhead? CostCenter and a value of the developer's name. Use the required-tags AWS Config managed rule to check for the tag. Create an AWS Lambda function to terminate resources that do not have the tag. Configure AWS Cost Explorer to send a daily report to each developer to monitor their spending. budget alerts for actual and forecast values to notify developers when they exceed or expect to exceed their assigned budget. Use AWS Budgets actions to apply a 551 Global IT Certification Hub DenyAll policy to the developer's IAM role to prevent additional resources from being launched when the assigned budget is reached. account. Configure Cost Explorer to send a daily report to each developer to monitor their spending. Use AWS Cost Anomaly Detection to detect anomalous spending and provide alerts. limited cost range. Create AWS Lambda functions in each AWS account to stop running resources at the end of each work day. Configure the Lambda functions to resume the resources at the start of each work day.,Instruct each developer to tag all their resources with a tag that has a key of,Use AWS Budgets to establish budgets for each developer account. Set up,Use AWS Cost Explorer to monitor and report on costs for each developer,Use AWS Service Catalog to allow developers to launch resources within a,,,B,"=IF(H63=I63,1,0)",Design Secure Architectures
Q63,"A company uses AWS Cost Explorer to monitor its AWS costs. The company notices that Amazon Elastic Block Store (Amazon EBS) storage and snapshot costs increase every month. However, the company does not purchase additional EBS storage every month. The company wants to optimize monthly costs for its current storage usage. Which solution will meet these requirements with the LEAST operational overhead? Amazon EBS. Use Amazon EBS Elastic Volumes to reduce the size of the EBS volumes. to reduce the size of the EBS volumes. create and manage the snapshots according to the company's snapshot policy requirements.",Use logs in Amazon CloudWatch Logs to monitor the storage utilization of,Use a custom script to monitor space usage. Use Amazon EBS Elastic Volumes,Delete all expired and unused snapshots to reduce snapshot costs.,Delete all nonessential snapshots. Use Amazon Data Lifecycle Manager to,,,D,"=IF(H64=I64,1,0)",Design Cost-Optimized Architectures
Q64,A company wants to run its experimental workloads in the AWS Cloud. The company has a budget for cloud spending. The company's CFO is concerned about cloud spending accountability for each department. The CFO wants to receive notification when the spending threshold reaches 60% of the budget. Which solution will meet these requirements? budgets in AWS Budgets. Add an alert threshold to receive notification when spending exceeds 60% of the budget. Cost Anomaly Detection to create alert threshold notifications when spending exceeds 60% of the budget. API on AWS Trusted Advisor to create alert threshold notifications when spending 486 Global IT Certification Hub exceeds 60% of the budget. budgets in AWS Budgets. Add an alert threshold to receive notification when spending exceeds 60% of the budget.,Use cost allocation tags on AWS resources to label owners. Create usage,Use AWS Cost Explorer forecasts to determine resource owners. Use AWS,Use cost allocation tags on AWS resources to label owners. Use AWS Support,Use AWS Cost Explorer forecasts to determine resource owners. Create usage,,,A,"=IF(H65=I65,1,0)",Design Cost-Optimized Architectures
Q65,A global ecommerce company uses a monolithic architecture. The company needs a solution to manage the increasing volume of product data. The solution must be scalable and have a modular service architecture. The company needs to maintain its structured database schemas. The company also needs a storage solution to store product data and product images. Which solution will meet these requirements with the LEAST operational overhead? containerized application. Use an Application Load Balancer to distribute web traffic. Use an Amazon RDS DB instance to store product data and product images. 604 Global IT Certification Hub Amazon DynamoDB to store product data and product images. Use Amazon Simple Notification Service (Amazon SNS) for event-driven communication between the Lambda functions. deployment to deploy a containerized application. Use an Amazon Aurora cluster to store the product data. Use AWS Step Functions to manage workflows. Store the product images in Amazon S3 Glacier Deep Archive. deploy a containerized application. Use Amazon RDS with a Multi-AZ deployment to store the product data. Store the product images in an Amazon S3 bucket.,Use an Amazon EC2 instance in an Auto Scaling group to deploy a,Use AWS Lambda functions to manage the existing monolithic application. Use,Use Amazon Elastic Kubernetes Service (Amazon EKS) with an Amazon EC2,Use Amazon Elastic Container Service (Amazon ECS) with AWS Fargate to,,,D,"=IF(H66=I66,1,0)",Design Resilient Architectures

SUMMARY,,,,,,,,Total Score:,=SUM(J2:J66),
,,,,,,,,Percentage:,=J68/65*100,
